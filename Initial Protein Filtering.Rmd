---
title: "Initial Protein Filtering"
output:
  html_document:
    df_print: paged
---

This notebook takes input files from IDPicker and generates a final list of VIR-CLASP hits ("binding proteins") by applying filters to the list. Here is a brief summary of the filtering steps:

0. Ensure proteins have >= 2 unique peptides and >= 20% sequence coverage (not included in Sankey)

1. Remove proteins that are not present in all 3 experimental replicates

2. Remove proteins that are part of the CRAPome list of common mass-spec contaminants. 
  -Experiment IDs used to generate CRAPome list are: CC405, CC406, CC410
  -CRAPome list narrowed to proteins with an average spectra in the 3 experiments of >=2

3. Remove proteins that are present in both control samples

A Sankey diagram of the filtering process will be generated at the end of the analysis. The "raw" data file and "final" data file will be saved to an Output folder. To save the intermediate files from the filtering, uncomment the last code chunk.


```{r setup}
library(tidyverse)
library(here)
library(networkD3)

#Function definitions
read_files <- function(file_name) {
  temp <- read_tsv(here("Input", file_name), progress = FALSE) %>%
    select("Accession", "Description", "Filtered Spectra", "Distinct Peptides", "Coverage") %>%
    mutate(source = str_replace(file_name, "\\.tsv", ""))
}

```



##Input of data files
-Split into Experimental (Exp) and no4SU control (Ctr) samples
-Remove decoys
-Perform Filter 0
-Clean up the Accessions
-Generate a histogram of Filtered Spectra and a count of total experimental proteins and control proteins. Log transform because of high number of low counts
```{r message = FALSE, echo = FALSE}
unfiltered_data <- map_df(list.files(here("Input")), read_files)

filter0 <- unfiltered_data %>%
  filter(!grepl("XXX", Accession)) %>%
  filter(`Distinct Peptides` >= 2 & Coverage >= 20) %>%
  separate(Accession, into = c("Trash", "Accession", "ID"), sep = "\\|", extra = "drop") %>%
  select(-Trash, -`Distinct Peptides`, -Coverage)

#Split into Experimental (Exp) and no4SU control (Ctr) samples

filter0_Exp <- filter0 %>%
  filter(!grepl("no4SU", source))

filter0_Ctr <- filter0 %>%
  filter(grepl("no4SU", source))

#Make plots
ggplot(filter0_Exp, aes(x = log(`Filtered Spectra`))) +
  geom_density() +
  ggtitle(label = paste("Experimental samples. N across conditions/replicates =", n_distinct(filter0_Exp$Accession)))

ggplot(filter0_Ctr, aes(x = log(`Filtered Spectra`))) +
  geom_density() +
  ggtitle(label = paste("Experimental samples. N across conditions/replicates =", n_distinct(filter0_Ctr$Accession)))
```


##Filter 1: Remove proteins that are not present in all 3 experimental replicates

```{r}
filter1 <- filter0_Exp %>%
  separate(col = "source", into = c("Timepoint", "IFN", "Replicate"), sep = "_") %>%
  group_by(Timepoint, IFN, Accession) %>%
  mutate(exists = sum(`Filtered Spectra` > 0)) %>%
  filter(exists == 3) %>%
  select(-exists, -`Filtered Spectra`, -Replicate) %>%
  unique()

print(paste("Number of unique proteins after Filter 1: ", n_distinct(filter1$Accession)))
```

##Filter 2: Remove proteins that are part of the CRAPome list of common mass-spec contaminants.
-Read in CRAPome file, then remove entries with fewer than 2 average spectral counts

```{r message = FALSE}
crapome <- read_csv(here("Crapome.csv")) %>%
  filter(AVE_SC >= 2)

filter2 <- filter1 %>%
  filter(!(ID %in% crapome$UNIPROT_ID))

print(paste("Number of unique proteins after Filter 2: ", n_distinct(filter2$Accession)))
```

##Filter 3: Remove proteins that are present in both control samples
-Create control datasets from filter0_Ctr for minus and plus IFN. Proteins limited to those present in both control replicates 
-Remove proteins based on IFN condition (filter3_minus, filter3_plus), then re-combine for final dataset

```{r}
Ctr_minus <- filter0_Ctr %>%
  separate(col = "source", into = c("Trash", "IFN", "Replicate"), sep = "_") %>%
  filter(IFN == "minus") %>%
  select(-Trash, -IFN) %>%
  group_by(Accession) %>%
  mutate(exists = sum(`Filtered Spectra` > 0)) %>%
  filter(exists == 2)

Ctr_plus <- filter0_Ctr %>%
  separate(col = "source", into = c("Trash", "IFN", "Replicate"), sep = "_") %>%
  filter(IFN == "plus") %>%
  select(-Trash, -IFN) %>%
  group_by(Accession) %>%
  mutate(exists = sum(`Filtered Spectra` > 0)) %>%
  filter(exists == 2)

filter3_minus <- filter2 %>%
  filter(IFN == "minus") %>%
  filter(!(Accession %in% Ctr_minus$Accession))

filter3_plus <- filter2 %>%
  filter(IFN == "plus") %>%
  filter(!(Accession %in% Ctr_minus$Accession))

filter3 <- bind_rows(filter3_minus, filter3_plus)

print(paste("Number of unique proteins after Filter 3: ", n_distinct(filter3$Accession)))

#Save as RDS for later analysis
saveRDS(filter3, file = "CHIKV_Hits.rds")
```


##Sankey generation
-Code adapted from: https://www.r-graph-gallery.com/321-introduction-to-interactive-sankey-diagram-2/
```{r fig.width = 10, fig.height = 6}
# 1 ------ CONNECTION DATA FRAME
 
# Usually what you have is a connection data frame: a list of flows with intensity for each flow
links=data.frame(source=c("Unfiltered","Unfiltered", 
                          "In all replicates", "In all replicates", 
                          "Not in CRAPome", "Not in CRAPome"), 
                 target=c("In all replicates","Not in all replicates", "Not in CRAPome", "CRAPome known contaminant", "Final Dataset", "ID'ed in negative control"), 
                 value=c(n_distinct(filter1$Accession),
                         (n_distinct(filter0_Exp$Accession) - n_distinct(filter1$Accession)),
                         n_distinct(filter2$Accession),
                         (n_distinct(filter1$Accession) - n_distinct(filter2$Accession)),
                         n_distinct(filter3$Accession),
                         n_distinct(filter2$Accession) - n_distinct(filter3$Accession)))
 
# From these flows we need to create a node data frame: it lists every entities involved in the flow
nodes=data.frame(name=c(as.character(links$source), as.character(links$target)) %>% unique())
 
# With networkD3, connection must be provided using id, not using real name like in the links dataframe.. So we need to reformat it.
links$IDsource=match(links$source, nodes$name)-1 
links$IDtarget=match(links$target, nodes$name)-1
 
# Make the Network
sankeyNetwork(Links = links, Nodes = nodes,
              Source = "IDsource", Target = "IDtarget",
              Value = "value", NodeID = "name", 
              fontSize = 15, nodeWidth = 30, 
              units = "Proteins", sinksRight=FALSE)
```














